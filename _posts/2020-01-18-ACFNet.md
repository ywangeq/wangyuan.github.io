---
layout:     post
title:      Reading
subtitle:   ACFNet- Attentional Class Feature Network for Semantic Segmentation
date:       2020-01-17
author:     WY
header-img: img/post-bg-ios9-web.jpg
catalog: true
tags:
    - Reading
    - Semantic Segmentation
---

> 年前最后一篇reading
总的来说，本篇文章还是基于一个注意力机制，来获得更好的context的paper.

<head>
    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
            tex2jax: {
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
            inlineMath: [['$','$']]
            }
        });
    </script>
</head>

## Motivation
作者认为，每个类的特征都是符合一定规律分布的，虽然在各个类别的边界处可能存在较大的相似性，
但是每个类的中心特征应该相差就砸，所以尝试着去获取各类的特征分布中心，然后根据像素特征与中心特征的距离来进行语义分类

![baseline](https://raw.githubusercontent.com/ywangeq/ywangeq.github.io/master/img/ACFNet_baseline.png)

## 流程
- 1.从*baseline*我们可以发现，文章直接用一个网络去提取图片的一个概率map，我们可以称之为*coarse map*, 
这是因为语义分割是一个end-to-end的task，在结果没出来前无法知道像素的分类。

> 这边我有一个问题，我不太确定生成这个coarse map的是映射过19类还是，还是不需要，没看代码， 后面假设我们得到了这个map

- 2. 我们知道空间层面的上下文获取方法是通过不同的感受视野来得到的，而本文中的类别层面上的context是通过高维特征和得到coarse分割的结果来计算获取的，类似一个feature到category的映射。
- 3. 从网络结构上我们可以看出来是一个coarse-refine的结构，先获得粗糙的map再通过ACF模块进行优化。
- 4. 我们可以着重关注两个模块 CCB（class Center Block） 和类注意模块(CAB) 

![CCB](https://raw.githubusercontent.com/ywangeq/ywangeq.github.io/master/img/ACFNet-CCB.png)
### CCB

其实看图就基本能了解了，从coarse map得到一个语义分割的类概率，然后取球每个类特征的中心

![CAB](https://raw.githubusercontent.com/ywangeq/ywangeq.github.io/master/img/ACFNet-CAB.png)
### CAB 
作者根据每个点所属类的概率与各类中心相乘，就可以得到这个点由类中心信息的特征，在与之前baseline的特征一起做最后的输出

### 结论
看结果的话，有不小的提升，但是我不明白为什么要加ASPP,本文不是聚焦在类间关系吗，ASPP 是空间上下文的提取module把
吧？