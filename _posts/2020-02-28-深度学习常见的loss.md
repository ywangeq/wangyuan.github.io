---
layout:     post
title:      深度学习
subtitle:   基本loss(交叉熵,focal loss)
date:       2020-02-27
author:     WY
header-img: img/post-bg-ios9-web.jpg
catalog: true
tags:
    - 基本考点
    - 深度学习
---
<head>
    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
            tex2jax: {
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
            inlineMath: [['$','$']]
            }
        });
    </script>
</head>

##### Focal loss
<font size="2">
Focal loss主要是为了解决one-stage目标检测中正负羊背比例严重失衡的问题。该损失函数降低了大量简单负样本在训练中所占的权重，何以理解为一种困难样本挖掘

1. 损失函数形式
Focal loss 是在交叉熵损失函数基础上进行的修改，首先回顾二分类交叉损失：

$L=-ylog\bar{y}-(1-y)log(1-\bar{y})$
if y=1 : $L=-log\bar{y}$
if y=0 : $L=-log(1-\bar{y})$

$\bar{y}$可以认为是最后的map结果，经过了激活函数的输出，所以在[0,1]之间。不难发现，普通的交叉熵对于正样本而言，输出概率越大损失越小。
对于负样本而言，输出概率越小则损失越小。此时的损失函数在大量简单样本的迭代过程中比较缓慢而且可能无法优化到最优，基于这个问题
$$ L_{fl}=
\begin{cases}
                -(1-\bar{y})^\gamma *log\bar{y}& y=1\\
                -\bar{y}^{\gamma}*log(1-\bar{y})& y=0
                \end{cases}$$

</font><br />